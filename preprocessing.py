"""
Module de pr√©traitement pour le projet de pr√©diction de churn
Contient le pipeline complet de transformation des donn√©es
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from feature_engineering import extract_all_features
from config import MODEL_FEATURES, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, COLUMNS_TO_DROP


def encode_categorical_features(df):
    """
    Encode les variables cat√©gorielles avec One-Hot Encoding

    Args:
        df: DataFrame avec les colonnes cat√©gorielles

    Returns:
        DataFrame: DataFrame avec les colonnes encod√©es
    """
    df = df.copy()

    print("Encodage des cat√©gories...")

    # Encodage de Gender
    if 'Gender' in df.columns:
        print("  ‚îú‚îÄ Encodage Gender...")
        gender_dummies = pd.get_dummies(df['Gender'], prefix='Gender', drop_first=False)
        df = pd.concat([df, gender_dummies], axis=1)

    # Encodage de Segment
    if 'Segment' in df.columns:
        print("  ‚îú‚îÄ Encodage Segment...")
        segment_dummies = pd.get_dummies(df['Segment'], prefix='Segment', drop_first=False)
        df = pd.concat([df, segment_dummies], axis=1)

    print("Encodage termin√©")

    return df


def normalize_features(df, scaler=None, fit=False):
    """
    Normalise les features num√©riques avec StandardScaler

    Args:
        df: DataFrame avec les features num√©riques
        scaler: StandardScaler pr√©-entra√Æn√© (None pour en cr√©er un nouveau)
        fit: Si True, fit le scaler sur les donn√©es (training), sinon transform seulement (prediction)

    Returns:
        tuple: (DataFrame normalis√©, scaler)
    """
    df = df.copy()

    print("Normalisation des features...")

    # Identifier les features num√©riques pr√©sentes
    numerical_cols = [col for col in NUMERICAL_FEATURES if col in df.columns]

    if len(numerical_cols) == 0:
        print("  Aucune feature num√©rique trouv√©e")
        return df, scaler

    print(f"  ‚îú‚îÄ {len(numerical_cols)} features √† normaliser")

    # Cr√©er un scaler si n√©cessaire
    if scaler is None:
        scaler = StandardScaler()

    # Fit et transform ou seulement transform
    if fit:
        print("  ‚îú‚îÄ Fit + Transform")
        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
    else:
        print("  ‚îú‚îÄ Transform seulement")
        df[numerical_cols] = scaler.transform(df[numerical_cols])

    print("Normalisation termin√©e")

    return df, scaler


def clean_dataframe(df):
    """
    Supprime les colonnes inutiles apr√®s le preprocessing

    Args:
        df: DataFrame √† nettoyer

    Returns:
        DataFrame: DataFrame nettoy√©
    """
    df = df.copy()

    print("üßπ Nettoyage du DataFrame...")

    # Supprimer les colonnes qui existent dans le DataFrame
    cols_to_drop = [col for col in COLUMNS_TO_DROP if col in df.columns]

    if cols_to_drop:
        print(f"  ‚îú‚îÄ Suppression de {len(cols_to_drop)} colonnes")
        df = df.drop(columns=cols_to_drop, errors='ignore')

    print("Nettoyage termin√©")

    return df


def select_model_features(df, required_features=None):
    """
    S√©lectionne uniquement les features n√©cessaires pour le mod√®le

    Args:
        df: DataFrame avec toutes les features
        required_features: Liste des features requises (par d√©faut MODEL_FEATURES)

    Returns:
        DataFrame: DataFrame avec uniquement les features s√©lectionn√©es
    """
    if required_features is None:
        required_features = MODEL_FEATURES

    print(f"S√©lection des features pour le mod√®le...")

    # V√©rifier quelles features sont disponibles
    available_features = [f for f in required_features if f in df.columns]
    missing_features = [f for f in required_features if f not in df.columns]

    if missing_features:
        print(f"  Features manquantes: {missing_features}")

    print(f"  ‚îú‚îÄ {len(available_features)}/{len(required_features)} features disponibles")

    return df[available_features].copy()


def preprocess_for_training(df):
    """
    Pipeline complet de pr√©traitement pour l'entra√Ænement du mod√®le

    Args:
        df: DataFrame brut avec les donn√©es originales

    Returns:
        tuple: (X_processed, y, scaler)
            - X_processed: Features pr√©trait√©es
            - y: Variable cible (si pr√©sente)
            - scaler: StandardScaler entra√Æn√©
    """
    print("D√©but du preprocessing pour entra√Ænement...")
    print("="*60)

    # 1. Extraction des features depuis les champs JSON
    df = extract_all_features(df)

    # 2. Encodage des variables cat√©gorielles
    df = encode_categorical_features(df)

    # 3. Normalisation des features num√©riques (avec fit)
    df, scaler = normalize_features(df, scaler=None, fit=True)

    # 4. Nettoyage du DataFrame
    df = clean_dataframe(df)

    # 5. Extraction de la variable cible (si pr√©sente)
    y = None
    if 'ChurnLabel' in df.columns:
        y = df['ChurnLabel'].copy()
        df = df.drop(columns=['ChurnLabel'])

    # 6. S√©lection des features finales
    X = select_model_features(df)

    print("="*60)
    print(f"Preprocessing termin√©: {X.shape[0]} lignes √ó {X.shape[1]} features")

    return X, y, scaler


def preprocess_for_prediction(df, scaler):
    """
    Pipeline complet de pr√©traitement pour la pr√©diction

    Args:
        df: DataFrame brut avec les donn√©es √† pr√©dire
        scaler: StandardScaler pr√©-entra√Æn√©

    Returns:
        DataFrame: Features pr√©trait√©es pr√™tes pour la pr√©diction
    """
    print("D√©but du preprocessing pour pr√©diction...")
    print("="*60)

    # 1. Extraction des features depuis les champs JSON
    df = extract_all_features(df)

    # 2. Encodage des variables cat√©gorielles
    df = encode_categorical_features(df)

    # 3. Normalisation des features num√©riques (sans fit, juste transform)
    df, _ = normalize_features(df, scaler=scaler, fit=False)

    # 4. Nettoyage du DataFrame (garder les colonnes utiles pour l'affichage)
    # On ne nettoie pas compl√®tement pour garder les infos clients

    # 5. S√©lection des features finales pour le mod√®le
    X = select_model_features(df)

    print("="*60)
    print(f"Preprocessing termin√©: {X.shape[0]} lignes √ó {X.shape[1]} features")

    return X


def validate_preprocessing(df_original, df_processed):
    """
    Valide que le preprocessing s'est correctement d√©roul√©

    Args:
        df_original: DataFrame original avant preprocessing
        df_processed: DataFrame apr√®s preprocessing

    Returns:
        dict: Dictionnaire avec les r√©sultats de validation
    """
    validation = {
        'original_shape': df_original.shape,
        'processed_shape': df_processed.shape,
        'missing_values': df_processed.isnull().sum().sum(),
        'features_created': list(df_processed.columns),
        'success': True
    }

    # V√©rifier qu'on a toutes les features n√©cessaires
    missing_features = [f for f in MODEL_FEATURES if f not in df_processed.columns]
    if missing_features:
        validation['success'] = False
        validation['missing_features'] = missing_features

    # V√©rifier qu'il n'y a pas de valeurs manquantes critiques
    if validation['missing_values'] > 0:
        validation['warning'] = f"{validation['missing_values']} valeurs manquantes d√©tect√©es"

    return validation


def get_feature_importance_data(df):
    """
    Pr√©pare les donn√©es pour afficher l'importance des features

    Args:
        df: DataFrame avec les features

    Returns:
        DataFrame: Statistiques sur les features
    """
    stats = pd.DataFrame({
        'Feature': df.columns,
        'Mean': df.mean(),
        'Std': df.std(),
        'Min': df.min(),
        'Max': df.max(),
        'Missing': df.isnull().sum()
    })

    return stats.reset_index(drop=True)
